\section{Accessibility Evaluation}

\subsection{Validation}

\paragraph{Evaluation methodology}
We ensured that the page validated using a combination of the W3C
validator\cite{w3validator} and the
`HTML CodeSniffer' JavaScript tool\cite{htmlcodesniffer}. The W3C
validator is the accepted standard for validation, and provided us
with the most rigourous check; the CodeSniffer tool is quicker and
more convenient to use while developing, helping us to avoid creating
issues in the first place.

No real `flaws' were uncovered as a result of this process.

\subsection{Labels and alternatives}

\paragraph{Evaluation methodology}
To ensure that the all appropriate elements had labels and text
alternatives, we used the `HTML CodeSniffer' JavaScript tool; this
tool is capable of checking all of the code-level criteria associated
with the WCAG 2.0 set of web accessibility guidelines\cite{wcag2}, up to level AAA, and will flag up missing labels and
text alternatives as errors. It found enough issues that we are
reasonably confident that it is accurate.

\paragraph{Issues found}
The design of our website does not make extensive use of images, so
there was not much scope for them to cause accessibility
issues. However, when checking for image text alteratives, we found
that while we had normally added alternative text for meaningful
images (such as clickable icons) without needing to pay explicit
attention to it, `decorative' images, such as the picture of each
finished dish, were left without text alternatives until the audit
called attention to it. This would have presented a potentially
serious accessibility issue, as the user of a screenreader, for
example, would have no way of knowing that those images were
meaningless.

For the most part, our initial design had contained labels for all
links and form controls, as a natural consequence of the text-oriented
design. The only unlabelled control was the text-input box for the
site-wide search, which (following a pattern established by many other
websites) was mainly described by the immediately adjacent `Search'
button. In this case, rather than adding an extra `Search' label,
which would only be visually confusing, we added a \verb!title!
attribute to the input box to ensure that a screen-reader-user could
determine its purpose.

\subsection{Semantic Markup}

\paragraph{Evaluation Methodology}
We evaluated the semantic structure of the markup using a combination
of HTML CodeSniffer's WCAG2.0AAA validation---obviously this can only
detect a subset of issues, but while it cannot infer the real semantic
meaning of elements it uses heuristics to identify `surprising'
markup, which can often indicate areas which should be checked
manually---manual inspection of the HTML, and the DOM inspection tools
provided by browsers.

\paragraph{Issues Found}
By paying attention to the semantic structure of the document during
the design phase, we pre-empted many issues here: the list of
instructions is just a heavily-styled \verb!<ol>!, for example.

There are a few areas where the appropriate semantic markup is less
obvious: for example, the recipe metadata---category, difficulty,
cooking time, etc.---could be presented as a table or just as a list
of text; in this case, we erred on the side of simplicity.

There were some fundamentally intractable semantic issues resulting
from the general lack of semantic richness in HTML, even after the
improvements with HTML5; fixing these accessibility problems is
outside the scope of this project.

There were also a few instances where heading elements (\verb!h1!,
\verb!h2!, etc.) had been used while prototyping for their visual
effect, resulting in an inconsistent outline for some pages. This
would have presented acessibility problems to anyone using a
screenreader that used the heading structure to help understand the
document. This was easily fixed by restyling the logical headings.

\subsection{Keyboard}

\subsubsection{Evaluation Methodology}

To ensure that the website was keyboard-navigable (useful not only for
power users, but also as an indication of whether the website is
likely to be navigable to users with other accessibility issues), we
wanted to establish that the following conditions were true:

\begin{itemize}
\item Tabbing through elements gives feedback on currently focused
  element.
\item All tab-focusable elements can be activated sensibly by Enter.
\item All functionality specified in the requirements can be accessed
  using the keyboard.
\end{itemize}

To check the first two properties, we went through each page (counting
the search and recipe pages as one page each, rather than expanding
all the combinatoric options), tabbing through to ensure that we could
see the focus location at all times, and checking that the Enter key
behaved as expected.

To check the third property, we went through each functional
requirement and attempted to fulfil it using only the keyboard (as we
were checking for keyboard-navigability, we used our extensive
knowledge of the structure of the site, glossing over temporarily the
issue of discoverable keyboard navigation).

\subsubsection{Issues Found}

In doing this, we found a number of issues:

\paragraph{Highlighting of focused elements.}
Several interactive elements with more complex visual styling---in
particular, the buttons in the header bar and for selecting the level
of detail at which to show recipes---had, in the process, lost the
builtin visual feedback showing which element was selected for
keyboard navigation. This is ironic, as much of the visual styling of
these elements existed to provide more feedback for mouse-based
navigation.

These issues were generally easy to fix using the \verb!:focus!
  pseudo-selector to replicate the browser built-in focus feedback
  (with increased emphasis in some cases to cut through the visual
  complexity).

\paragraph{Keyboard activation of extra interactive functionality.}
Richer pieces of interaction further from the original
hypertext-document model of the web web (in particular, the popup help
and tickable instructions) inherited no default keyboard-navigability
from the browser, and were for some time impossible to control from
the keyboard. This is particularly embarrasing given that the author
of this functionality uses a keyboard-oriented browser with an
interface borrowed from the \textsc{Unix} editor \verb!vim! for
regular browsing.

These issues were more problematic to resolve, as the \verb!onclick!
  event (also fired by keyboard activation) is not consistently bound
  to keyboard activation except in the case of \verb!a!,
  \verb!button!, and \verb!input! elements. This required a few
  slightly irritating changes to the markup and styling of the
  application.

\paragraph{Tab order of search filters}
The search filter form (in our design) sits naturally on the right,
both for visual effect and inter-application consistency (many other
applications with filterable searches place the filters in the right
margin of the results, as a good compromise between being easy to
reach and not distracting from the results).

This places the `natural' tab order for search filters \emph{after}
all search results: this is very inconvenient---tabbing through a few
consistent form elements to reach the results would not be too bad,
but tabbing through a large and variable number of search results to
reach the filters is very annoying.

Part of the solution to this is obviously to place the filters earlier
in the tab order; we did this by placing the filter form before the
results in the DOM, as part of our effort to ensure that the site
would respond tolerably to small browser windows.

However, this introduces a new issue---tabbing now causes the focus to
`skip' across the first few results, which appear visually ``before''
the filters in a left-to-right reading. This could cause the user to
lose track of the focused location.

To resolve this, we added dynamic styling which calls attention to the
filter box whenever one of its elements is selected.

\subsection{Feedforward and Feedback}

\subsubsection{Evaluation Methodology}

To systematically evaluate our application from a feedforward and
feedback point of view, we examined each interactive element on each
page, and listed out the visual, dynamic, and textual feedforward cues
it provided, the user-visible feedback cues presented on using
it, and the real consequences caused by using it.

For each element, we considered these three pieces of data
(feedforward cues, feedback cues, and consequences) and arrived at our
best determination of whether the element had adequate feedforward and
feedback. This was a fairly ad-hoc process done by individuals at
various points over the course of the project, although it seemed
fairly effective. In retrospect, however, it would have been valuable
to explicitly borrow many of the techniques from the CHE---one person
compiling the lists of elements, cues, and consequences, and then the
group performing a collaborative evaluation directed by those lists
rather than by heuristics. But what we did seemed to work reasonably.

Obviously this process is very subjective and rather
error-prone. Fortunately, it was a supplement to the other evaluations
we had (Collaborative Heuristic and Task-Based); the Task-Based
evaluation in particular really exercised the feedback and feedforward
properties of our application, (the issues it raised were covered
there).

\subsubsection{Issues Found}

\paragraph{Ticking off instructions}
One relatively early issue we uncovered was that the cues around the
`ticking off completed instructions' steps were wholly inadequate. In
the version with this issue, instruction steps were presented as an
unadorned list of paragraphs; hovering over each step would cause it
to be coloured a dark blue, and clicking on the step would cause it to
be styled as `strikethrough' text. This satisfied the functional
requirement, but the feedback was potentially unclear, and feedforward
was entirely absent.

To address this issue, we styled the list with an empty check-box next
to each instruction step---making the suggestion that each step is
checkable. Hovering over a step then places a tick in the checkbox,
and fades out slightly. Clicking on the step then keeps the tick in
the checkbox, and fades the step out further to call attention to the
subsequent, unfaded, instruction steps. We feel that this represents a
significant improvement in feedforward in particular, as well as
making the ticking-off feature more useful by deemphasising completed
steps.

There is still some awkwardness integrating feedforward with feedback
for this element: after ticking off a step, you have the opportunity
to undo that by clicking on the step again. Feedforward for this undo
operation suggests that the element should give an indication of what
that will do, but this conflicts with providing feedback for the
ticking-off operation (as the user will inevitably be hovering
immediately after clicking, but the user does not get the best
feedback until the cursor is moved away from the element). We could
not find a simple mechanism that would provide good feedforward and
feedback for these transitions, but despite this, we feel that the
major issues with this functionality have been resolved.

\paragraph{Activation of search filters}
Evaluation and testing uncovered some issues with the application of
search filters, and the interaction between the top-banner search box
and the filtering controls further down the page. It took users some
time to be confident as to the effects of various filtering
operations.

We addressed the issue of interaction between filters and search box
by replicating the search box alongside the filtering controls
(scripting was used to ensure that the search terms were identical, to
prevent user confusion). This made it easy for the user to understand
the interaction between the text query and the filters.

To address the other issues, we altered the filtering controls so that
the list of results would update immediately on changing the values of
the filters. This gave the users immediate feedback on the effects of
their actions, allowing them to become comfortable with the filtering
more quickly. It also prevented the user from losing track of which
filters they would apply on pressing the `Filter' button.
